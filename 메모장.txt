cmd:
nvidia-smi : nvidia 버전확인

compile() : / loss='mse' : mean squared error / 실제 값과 예측값의 차이를 기준으로 오차를 판단하는 방식
            / optimizer='adam' : 아직 설명없음, adam이 국룰
//

batch_size : 데이터셋을 신경망에 여러 조각으로 나누어 넣을 때, 나눠 담는 데이터의 양. 디폴트 값=32

mlp = multi-layer perceptron : perceptron으로 이루어져있는 layer를 여러개 갖고 있는 형태.

//

1. data set을 읽는다.
2. 슬쩍 확인
3. isnull()로 결측치 확인. 결측치 있을 경우 (1) fillna()...
4. data encoding : pd.factorize(), replace(), LabelEncoder() ,,,
5. data normalization or standardization (데이터 정규화) : feature 값을 0~1의 값으로 바꾸거나     평균이 0, 분산이 1이 되도록 스케일링
5-1. 문제에 따라 column의 중요도? 파악
6. 데이터셋 스플릿(train, test)
7. modeling : 문제 해결에 가장 효율적인 모델 선정
8. compile, fit : 정확도(accuracy)를 올리기 위해 가장 중요하다고 표현한 사람도 있었던 optimizer(최적화 기법)를 잘 선택해야 한다...
???) 하이퍼 파라미터 튜닝을 할 때 grid search로 탐색후 진행하는 경우도 있었다. 
9. 예측, 평가 : 주로 보이는 평가 지표 confusion matrix, loss, acc, val_loss, val_acc ,,,,
10. 답안 제출

//

train_test_split() 에서 train_size 파라미터와 test_size 파라미터는 반비례되는 성질이지만, 그 합이 1이 안되어도 실행은 된다.(but, data 손실이 일어남)

plt.scatter : 점 찍기
   .plot    : 선 긋기

//

round(n) : 소수점 n 번째 자리에서 반올림

//

activation(활성화 함수) : 인공 신경망에서 입력을 변환하는 함수이다. ReLU, 시그모이드 함수, 쌍곡탄젠트 함수 등이 대표적인 활성화 함수이다.
model.fit( verbose= )   : verbose=0 : 침묵
                          verbose=1 : 디폴트
                          verbose=2 : 프로그래스바 삭제
                          verbose=나머지 : epoch 만 나옴
